---
title: "Team Project 2" 
author: "Abizer and Luis"
date: "Day 17"
output: 
  github_document:
    pandoc_args: --webtex
---
This code chunk ensures that there are no commands in output file

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse=TRUE, prompt=TRUE,comment=NULL,message=FALSE, echo = FALSE, include=TRUE, fig.width = 9, fig.height = 4)
```

Download the packages

```{r packageCheck, include=FALSE}
mypacks <- c("ggplot2","dplyr","readr","tidyr", "ROCR", "boot","class","randomForest","e1071", "stringr","partykit","rpart","plyr")  # what packages are needed?
packs <- installed.packages()   # find installed package list
install.me <- mypacks[!(mypacks %in% packs[,"Package"])]  #what needs to be installed?
if (length(install.me) >= 1) install.packages(install.me, repos = "http://cran.us.r-project.org")   # install (if needed)
lapply(mypacks, library, character.only=TRUE)  # load all packages
```


Read the key file
```{r}
key <- read.csv("https://raw.githubusercontent.com/mgelman/data/master/county_facts_dictionary.csv")
```

Create the train and test dataframes
```{r}
train <- read_csv("https://raw.githubusercontent.com/mgelman/data/master/train.csv")
test <- read_csv("https://raw.githubusercontent.com/mgelman/data/master/test_No_Y.csv")
```

Define a winner variable, which is based on winner16 variable. Winner is set as Democrat if winner16 is Dem and Republican if winner16 is Rep

```{r}
train <- train %>% mutate(winner = recode_factor(winner16, Dem = "Democrat", Rep = "Republican"))
```

We chose the x-variables by determining which variables were most significant using a regression analysis. 



```{r}
library(plyr)

train1 <- train %>% plyr::rename(c("RTN130207"="Retail_Sales_07","INC910213"="Income_per_capita","HSG096213"="Percent_multi_unit_housing","POP715213"="Percent_living_in_same_house_multiple_years","HSG495213"="Median_house_value","POP815213"="Spoken_non_english_lang","EDU635213"="Percent_Highschool_grad","EDU685213"="Percent_Undergrad","AGE295214"="percent_under_18","AGE775214"="percent_over_65","PST120214"="percent_change_in_pop"))

test1 <- test %>% plyr::rename(c("RTN130207"="Retail_Sales_07","INC910213"="Income_per_capita","HSG096213"="Percent_multi_unit_housing","HSG495213"="Median_house_value","POP815213"="Spoken_non_english_lang","EDU635213"="Percent_Highschool_grad","POP715213"="Percent_living_in_same_house_multiple_years","EDU685213"="Percent_Undergrad","AGE295214"="percent_under_18","AGE775214"="percent_over_65","PST120214"="percent_change_in_pop")) 

Train1 <- train1 %>% select(Retail_Sales_07, Income_per_capita, Median_house_value,Percent_multi_unit_housing, Spoken_non_english_lang, Percent_Undergrad,  Percent_living_in_same_house_multiple_years, percent_change_in_pop, winner)

Test1 <- test1 %>% select(Retail_Sales_07, Income_per_capita, Median_house_value, Spoken_non_english_lang, Percent_multi_unit_housing,Percent_living_in_same_house_multiple_years, Percent_Undergrad, percent_change_in_pop)

xvars <- str_c(names(Train1)[1:8], collapse="+")
myform <- as.formula(str_c("winner ~ ", xvars))

winner.glm <- glm(myform, data = Train1, family = binomial)

summary(winner.glm)
```


We then fit the model "winner.glm" into the train and test data to create probabilities. We then set a threshold of 0.05. For example, if the model determines the probability to be 0.1, prediction will be Republican or else Democrat. We then calculated the accuracy, precision and recall for the model. Then, we created a double density curve

```{r}
train <- Train1 %>% mutate(probs = predict(winner.glm, type = "response"),prediction = ifelse(probs >= 0.05,"Republican","Democrat"))

test <- test1 %>% mutate(probs = predict(winner.glm, newdata = test1, type = "response"),prediction = ifelse(probs >= 0.05,"Republican","Democrat"))

train %>% summarize(accuracy = mean(winner == prediction), precision = sum(winner == "Republican" & prediction == "Republican")/sum(prediction == "Republican"), recall = sum(winner == "Republican" & prediction == "Republican")/sum(winner == "Republican"))

ggplot(train,aes(x = probs, color = winner)) + geom_density(size = 1.5) + ggtitle("Forecasted Winner Probabilities ")
```
The accuracy for the logistic regression model is 0.875

Here, we created a ROC curve for the training data
```{r}
preds_obj1 <- prediction(train$probs, train$winner, label.ordering=c("Democrat","Republican"))
perf_obj1 <- performance(preds_obj1, "tpr","fpr")
perf_df1 <- data_frame(fpr=unlist(perf_obj1@x.values),
                       tpr= unlist(perf_obj1@y.values),
                       threshold=unlist(perf_obj1@alpha.values), 
                       model="train")

ggplot(perf_df1, aes(x=fpr, y=tpr, color=model)) +  geom_line(size=1.5) + 
  labs(x="false positive rate", y="true positive rate", title="ROC curve for logistic regression") + 
  geom_abline(slope=1,intercept=0, linetype=3) 
```

I calculated the error of the model using a 5-fold cross validation and a 0.05 threshold
```{r}
set.seed(5)
cost <- function(y, pi) 1-mean(y==(pi>0.05))
train_error <- cv.glm(data = Train1, winner.glm,cost,5)
train_error$delta[1]
```
The error is 0.126

Random Forest

Created a random forest model with 300 trees that randomly select out of 5 variables at each split. Then we fitted the model to the training data and the testing data. We then calculated the accuracy, precision, recall and error for the training data predictions

```{r}
set.seed(5)

winner_rforest <- randomForest(myform,data = train, ntree = 400, mtry = 4)

train3 <- train %>% mutate(probs = predict(winner_rforest, type = "prob")[,2],prediction = predict(winner_rforest, type = "response"))

test3 <- test %>% mutate(prediction = predict(winner_rforest,type = "response",newdata = test))

train3 %>% summarize(accuracy = mean(winner == prediction), precision = sum(winner == "Republican" & prediction == "Republican")/sum(prediction == "Republican"), recall = sum(winner == "Republican" & prediction == "Republican")/sum(winner == "Republican"), error = 1 - accuracy)



```

The error is 0.09 and the accuracy is 0.91

Here, we used the k nearest neighbours model with k = 10. We then compute the accuracy, precision, recall and error for the model
K-nn 

```{r}
set.seed(7)
n <- nrow(train)

xvars <- str_c(names(Train1)[1:9], collapse=",")

train_index <- sample(1:n, size=round(.8*n))

trainX <- Train1 %>% slice(train_index) %>% select( -winner)

testX <- Test1 %>% slice(-train_index) 

dim(trainX)
dim(testX)
winner_knn <- knn(trainX,testX,cl = train$winner[train_index],k=10)

winner_knn.cv <- knn.cv(Train1[,c("Retail_Sales_07", "Income_per_capita", "Median_house_value","Percent_multi_unit_housing", "Spoken_non_english_lang", "Percent_Undergrad",  "Percent_living_in_same_house_multiple_years", "percent_change_in_pop")],cl = Train1$winner,k=50)

train_knn <- data_frame(y = Train1$winner, prediction = winner_knn.cv) 

train_knn %>% summarize(accuracy = mean(y == prediction), precision = sum(y == "Republican" & prediction == "Republican")/sum(prediction == "Republican"),recall = sum(y == "Republican" & prediction == "Republican")/sum(y == "Republican"), error = 1 - accuracy)
```
Error is 0.127 and accuracy is 0.873

We use random forest to predict our model. We added the predictions to the table test_No_Y and and created a csv file
```{r}
test_No_Y <- Test1 %>% mutate(pred_winner = predict(winner_rforest, type = "response",newdata = Test1))
write_csv(test_No_Y, "test_No_Y_LastNames.csv")
```
